{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rank x_class        date  region start_time max_time end_time  \\\n",
      "0      1    X28+  2003/11/04     486      19:29    19:53    20:06   \n",
      "1      2    X20+  2001/04/02    9393      21:32    21:51    22:03   \n",
      "2      3  X17.2+  2003/10/28     486      09:51    11:10    11:24   \n",
      "3      4    X17+  2005/09/07     808      17:17    17:40    18:03   \n",
      "4      5   X14.4  2001/04/15    9415      13:19    13:50    13:55   \n",
      "5      6     X10  2003/10/29     486      20:37    20:49    21:01   \n",
      "6      7    X9.4  1997/11/06    8100      11:49    11:55    12:01   \n",
      "7      8    X9.3  2017/09/06    2673      11:53    12:02    12:10   \n",
      "8      9      X9  2006/12/05     930      10:18    10:35    10:45   \n",
      "9     10    X8.3  2003/11/02     486      17:03    17:25    17:39   \n",
      "10    11    X8.2  2017/09/10    2673      15:35    16:06    16:31   \n",
      "11    12    X7.1  2005/01/20     720      06:36    07:01    07:26   \n",
      "12    13    X6.9  2011/08/09    1263      07:48    08:05    08:08   \n",
      "13    14    X6.5  2006/12/06     930      18:29    18:47    19:00   \n",
      "14    15    X6.2  2005/09/09     808      19:13    20:04    20:36   \n",
      "15    16    X6.2  2001/12/13    9733      14:20    14:30    14:35   \n",
      "16    17    X5.7  2000/07/14    9077      10:03    10:24    10:43   \n",
      "17    18    X5.6  2001/04/06    9415      19:10    19:21    19:31   \n",
      "18    19    X5.4  2012/03/07    1429      00:02    00:24    00:40   \n",
      "19    20    X5.4  2005/09/08     808      20:52    21:06    21:17   \n",
      "20    21    X5.4  2003/10/23     486      08:19    08:35    08:49   \n",
      "21    22    X5.3  2001/08/25    9591      16:23    16:45    17:04   \n",
      "22    23    X4.9  2014/02/25    1990      00:39    00:49    01:03   \n",
      "23    24    X4.9  1998/08/18    8307      22:10    22:19    22:28   \n",
      "24    25    X4.8  2002/07/23      39      00:18    00:35    00:47   \n",
      "25    26      X4  2000/11/26    9236      16:34    16:48    16:56   \n",
      "26    27    X3.9  2003/11/03     488      09:43    09:55    10:19   \n",
      "27    28    X3.9  1998/08/19    8307      21:35    21:45    21:50   \n",
      "28    29    X3.8  2005/01/17     720      06:59    09:52    10:07   \n",
      "29    30    X3.7  1998/11/22    8384      06:30    06:42    06:49   \n",
      "30    31    X3.6  2005/09/09     808      09:42    09:59    10:08   \n",
      "31    32    X3.6  2004/07/16     649      13:49    13:55    14:01   \n",
      "32    33    X3.6  2003/05/28     365      00:17    00:27    00:39   \n",
      "33    34    X3.4  2006/12/13     930      02:14    02:40    02:57   \n",
      "34    35    X3.4  2001/12/28    9767      20:02    20:45    21:32   \n",
      "35    36    X3.3  2013/11/05    1890      22:07    22:12    22:15   \n",
      "36    37    X3.3  2002/07/20      39      21:04    21:30    21:54   \n",
      "37    38    X3.3  1998/11/28    8395      04:54    05:52    06:13   \n",
      "38    39    X3.2  2013/05/14    1748      00:00    01:11    01:20   \n",
      "39    40    X3.1  2014/10/24    2192      21:07    21:41    22:13   \n",
      "40    41    X3.1  2002/08/24      69      00:49    01:12    01:31   \n",
      "41    42      X3  2002/07/15      30      19:59    20:08    20:14   \n",
      "42    43    X2.8  2013/05/13    1748      15:48    16:05    16:16   \n",
      "43    44    X2.8  2001/12/11    9733      07:58    08:08    08:14   \n",
      "44    45    X2.8  1998/08/18    8307      08:14    08:24    08:32   \n",
      "45    46    X2.7  2015/05/05    2339      22:05    22:11    22:15   \n",
      "46    47    X2.7  2003/11/03     488      01:09    01:30    01:45   \n",
      "47    48    X2.7  1998/05/06    8210      07:58    08:09    08:20   \n",
      "48    49    X2.6  2005/01/15     720      22:25    23:02    23:31   \n",
      "49    50    X2.6  2001/09/24    9632      09:32    10:38    11:09   \n",
      "\n",
      "                  movie  \n",
      "0   Movie  View archive  \n",
      "1   Movie  View archive  \n",
      "2   Movie  View archive  \n",
      "3   Movie  View archive  \n",
      "4   Movie  View archive  \n",
      "5   Movie  View archive  \n",
      "6   Movie  View archive  \n",
      "7   Movie  View archive  \n",
      "8   Movie  View archive  \n",
      "9   Movie  View archive  \n",
      "10  Movie  View archive  \n",
      "11  Movie  View archive  \n",
      "12  Movie  View archive  \n",
      "13  Movie  View archive  \n",
      "14  Movie  View archive  \n",
      "15  Movie  View archive  \n",
      "16  Movie  View archive  \n",
      "17  Movie  View archive  \n",
      "18  Movie  View archive  \n",
      "19  Movie  View archive  \n",
      "20  Movie  View archive  \n",
      "21  Movie  View archive  \n",
      "22  Movie  View archive  \n",
      "23         View archive  \n",
      "24  Movie  View archive  \n",
      "25  Movie  View archive  \n",
      "26  Movie  View archive  \n",
      "27         View archive  \n",
      "28  Movie  View archive  \n",
      "29  Movie  View archive  \n",
      "30  Movie  View archive  \n",
      "31  Movie  View archive  \n",
      "32  Movie  View archive  \n",
      "33  Movie  View archive  \n",
      "34  Movie  View archive  \n",
      "35  Movie  View archive  \n",
      "36  Movie  View archive  \n",
      "37  Movie  View archive  \n",
      "38  Movie  View archive  \n",
      "39  Movie  View archive  \n",
      "40  Movie  View archive  \n",
      "41  Movie  View archive  \n",
      "42  Movie  View archive  \n",
      "43  Movie  View archive  \n",
      "44         View archive  \n",
      "45  Movie  View archive  \n",
      "46  Movie  View archive  \n",
      "47  Movie  View archive  \n",
      "48  Movie  View archive  \n",
      "49  Movie  View archive  \n"
     ]
    }
   ],
   "source": [
    "# part 1\n",
    "## step 1\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "#Will http get request from SpaceWeatherLive website. Table is parsed using BeautifulSoup and Pandas.\n",
    "#Table is placed into a dataframe\n",
    "\n",
    "url = 'https://www.spaceweatherlive.com/en/solar-activity/top-50-solar-flares'\n",
    "\n",
    "#http get request\n",
    "r = requests.get(url, headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X x.y; rv:42.0) Gecko/20100101 Firefox/42.0'})\n",
    "\n",
    "table = BeautifulSoup(r.content).find('table')\n",
    "\n",
    "lst = pd.read_html(table.prettify())\n",
    "df1 = pd.DataFrame(lst[0])\n",
    "\n",
    "#renaming columns\n",
    "df1.rename(columns={'Unnamed: 0':'rank', 'Unnamed: 1':'x_class', 'Unnamed: 2':'date', 'Region':'region',\n",
    "                   'Start':'start_time', 'Maximum':'max_time', 'End':'end_time', 'Unnamed: 7':'movie'}, inplace=True)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rank x_class       start_datetime         max_datetime  \\\n",
      "0      1    X28+  2003-11-04 19:29:00  2003-11-04 19:53:00   \n",
      "1      2    X20+  2001-04-02 21:32:00  2001-04-02 21:51:00   \n",
      "2      3  X17.2+  2003-10-28 09:51:00  2003-10-28 11:10:00   \n",
      "3      4    X17+  2005-09-07 17:17:00  2005-09-07 17:40:00   \n",
      "4      5   X14.4  2001-04-15 13:19:00  2001-04-15 13:50:00   \n",
      "5      6     X10  2003-10-29 20:37:00  2003-10-29 20:49:00   \n",
      "6      7    X9.4  1997-11-06 11:49:00  1997-11-06 11:55:00   \n",
      "7      8    X9.3  2017-09-06 11:53:00  2017-09-06 12:02:00   \n",
      "8      9      X9  2006-12-05 10:18:00  2006-12-05 10:35:00   \n",
      "9     10    X8.3  2003-11-02 17:03:00  2003-11-02 17:25:00   \n",
      "10    11    X8.2  2017-09-10 15:35:00  2017-09-10 16:06:00   \n",
      "11    12    X7.1  2005-01-20 06:36:00  2005-01-20 07:01:00   \n",
      "12    13    X6.9  2011-08-09 07:48:00  2011-08-09 08:05:00   \n",
      "13    14    X6.5  2006-12-06 18:29:00  2006-12-06 18:47:00   \n",
      "14    15    X6.2  2005-09-09 19:13:00  2005-09-09 20:04:00   \n",
      "15    16    X6.2  2001-12-13 14:20:00  2001-12-13 14:30:00   \n",
      "16    17    X5.7  2000-07-14 10:03:00  2000-07-14 10:24:00   \n",
      "17    18    X5.6  2001-04-06 19:10:00  2001-04-06 19:21:00   \n",
      "18    19    X5.4  2012-03-07 00:02:00  2012-03-07 00:24:00   \n",
      "19    20    X5.4  2005-09-08 20:52:00  2005-09-08 21:06:00   \n",
      "20    21    X5.4  2003-10-23 08:19:00  2003-10-23 08:35:00   \n",
      "21    22    X5.3  2001-08-25 16:23:00  2001-08-25 16:45:00   \n",
      "22    23    X4.9  2014-02-25 00:39:00  2014-02-25 00:49:00   \n",
      "23    24    X4.9  1998-08-18 22:10:00  1998-08-18 22:19:00   \n",
      "24    25    X4.8  2002-07-23 00:18:00  2002-07-23 00:35:00   \n",
      "25    26      X4  2000-11-26 16:34:00  2000-11-26 16:48:00   \n",
      "26    27    X3.9  2003-11-03 09:43:00  2003-11-03 09:55:00   \n",
      "27    28    X3.9  1998-08-19 21:35:00  1998-08-19 21:45:00   \n",
      "28    29    X3.8  2005-01-17 06:59:00  2005-01-17 09:52:00   \n",
      "29    30    X3.7  1998-11-22 06:30:00  1998-11-22 06:42:00   \n",
      "30    31    X3.6  2005-09-09 09:42:00  2005-09-09 09:59:00   \n",
      "31    32    X3.6  2004-07-16 13:49:00  2004-07-16 13:55:00   \n",
      "32    33    X3.6  2003-05-28 00:17:00  2003-05-28 00:27:00   \n",
      "33    34    X3.4  2006-12-13 02:14:00  2006-12-13 02:40:00   \n",
      "34    35    X3.4  2001-12-28 20:02:00  2001-12-28 20:45:00   \n",
      "35    36    X3.3  2013-11-05 22:07:00  2013-11-05 22:12:00   \n",
      "36    37    X3.3  2002-07-20 21:04:00  2002-07-20 21:30:00   \n",
      "37    38    X3.3  1998-11-28 04:54:00  1998-11-28 05:52:00   \n",
      "38    39    X3.2  2013-05-14 00:00:00  2013-05-14 01:11:00   \n",
      "39    40    X3.1  2014-10-24 21:07:00  2014-10-24 21:41:00   \n",
      "40    41    X3.1  2002-08-24 00:49:00  2002-08-24 01:12:00   \n",
      "41    42      X3  2002-07-15 19:59:00  2002-07-15 20:08:00   \n",
      "42    43    X2.8  2013-05-13 15:48:00  2013-05-13 16:05:00   \n",
      "43    44    X2.8  2001-12-11 07:58:00  2001-12-11 08:08:00   \n",
      "44    45    X2.8  1998-08-18 08:14:00  1998-08-18 08:24:00   \n",
      "45    46    X2.7  2015-05-05 22:05:00  2015-05-05 22:11:00   \n",
      "46    47    X2.7  2003-11-03 01:09:00  2003-11-03 01:30:00   \n",
      "47    48    X2.7  1998-05-06 07:58:00  1998-05-06 08:09:00   \n",
      "48    49    X2.6  2005-01-15 22:25:00  2005-01-15 23:02:00   \n",
      "49    50    X2.6  2001-09-24 09:32:00  2001-09-24 10:38:00   \n",
      "\n",
      "           end_datetime  region  \n",
      "0   2003-11-04 20:06:00     486  \n",
      "1   2001-04-02 22:03:00    9393  \n",
      "2   2003-10-28 11:24:00     486  \n",
      "3   2005-09-07 18:03:00     808  \n",
      "4   2001-04-15 13:55:00    9415  \n",
      "5   2003-10-29 21:01:00     486  \n",
      "6   1997-11-06 12:01:00    8100  \n",
      "7   2017-09-06 12:10:00    2673  \n",
      "8   2006-12-05 10:45:00     930  \n",
      "9   2003-11-02 17:39:00     486  \n",
      "10  2017-09-10 16:31:00    2673  \n",
      "11  2005-01-20 07:26:00     720  \n",
      "12  2011-08-09 08:08:00    1263  \n",
      "13  2006-12-06 19:00:00     930  \n",
      "14  2005-09-09 20:36:00     808  \n",
      "15  2001-12-13 14:35:00    9733  \n",
      "16  2000-07-14 10:43:00    9077  \n",
      "17  2001-04-06 19:31:00    9415  \n",
      "18  2012-03-07 00:40:00    1429  \n",
      "19  2005-09-08 21:17:00     808  \n",
      "20  2003-10-23 08:49:00     486  \n",
      "21  2001-08-25 17:04:00    9591  \n",
      "22  2014-02-25 01:03:00    1990  \n",
      "23  1998-08-18 22:28:00    8307  \n",
      "24  2002-07-23 00:47:00      39  \n",
      "25  2000-11-26 16:56:00    9236  \n",
      "26  2003-11-03 10:19:00     488  \n",
      "27  1998-08-19 21:50:00    8307  \n",
      "28  2005-01-17 10:07:00     720  \n",
      "29  1998-11-22 06:49:00    8384  \n",
      "30  2005-09-09 10:08:00     808  \n",
      "31  2004-07-16 14:01:00     649  \n",
      "32  2003-05-28 00:39:00     365  \n",
      "33  2006-12-13 02:57:00     930  \n",
      "34  2001-12-28 21:32:00    9767  \n",
      "35  2013-11-05 22:15:00    1890  \n",
      "36  2002-07-20 21:54:00      39  \n",
      "37  1998-11-28 06:13:00    8395  \n",
      "38  2013-05-14 01:20:00    1748  \n",
      "39  2014-10-24 22:13:00    2192  \n",
      "40  2002-08-24 01:31:00      69  \n",
      "41  2002-07-15 20:14:00      30  \n",
      "42  2013-05-13 16:16:00    1748  \n",
      "43  2001-12-11 08:14:00    9733  \n",
      "44  1998-08-18 08:32:00    8307  \n",
      "45  2015-05-05 22:15:00    2339  \n",
      "46  2003-11-03 01:45:00     488  \n",
      "47  1998-05-06 08:20:00    8210  \n",
      "48  2005-01-15 23:31:00     720  \n",
      "49  2001-09-24 11:09:00    9632  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-24eeacba0393>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['start_time'][index] = datetime.strptime(row['date'] + ' ' + row['start_time'], '%Y/%m/%d %H:%M')\n",
      "<ipython-input-8-24eeacba0393>:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['max_time'][index] = datetime.strptime(row['date'] + ' ' + row['max_time'], '%Y/%m/%d %H:%M')\n",
      "<ipython-input-8-24eeacba0393>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['end_time'][index] = datetime.strptime(row['date'] + ' ' + row['end_time'], '%Y/%m/%d %H:%M')\n"
     ]
    }
   ],
   "source": [
    "# part 1\n",
    "## step 2\n",
    "\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "#First dataframe is deep copied into a new dataframe just because. The start_time, max_time, and end_time columns are \n",
    "#combined with date and the columns are renamed to start_datetime, max_datetime, and end_datetime respectively.\n",
    "#Removed 'movie' column\n",
    "\n",
    "#deep copying first dataframe \n",
    "df2 = df1.copy()\n",
    "\n",
    "#delete movie column\n",
    "df2 = df2.drop(columns=['movie'])\n",
    "\n",
    "#combining date and time\n",
    "for index, row in df2.iterrows():\n",
    "    df2['start_time'][index] = datetime.strptime(row['date'] + ' ' + row['start_time'], '%Y/%m/%d %H:%M')\n",
    "    df2['max_time'][index] = datetime.strptime(row['date'] + ' ' + row['max_time'], '%Y/%m/%d %H:%M')\n",
    "    df2['end_time'][index] = datetime.strptime(row['date'] + ' ' + row['end_time'], '%Y/%m/%d %H:%M')\n",
    "\n",
    "#dropping date\n",
    "df2 = df2.drop(columns=['date'])\n",
    "#renaming columns\n",
    "df2.rename(columns={'start_time':'start_datetime', 'max_time':'max_datetime', 'end_time':'end_datetime'}, inplace=True)\n",
    "#reorganizing columns\n",
    "df2 = df2[['rank', 'x_class', 'start_datetime', 'max_datetime', 'end_datetime', 'region']]\n",
    "\n",
    "#setting regions coded as - as missing (NaN)\n",
    "df2['region'] = df2['region'].replace('-', np.nan)\n",
    "\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     start_date start_time end_date end_time start_frequency end_frequency  \\\n",
      "0    1997/04/01      14:00    04/01    14:15            8000          4000   \n",
      "1    1997/04/07      14:30    04/07    17:30           11000          1000   \n",
      "2    1997/05/12      05:15    05/14    16:00           12000            80   \n",
      "3    1997/05/21      20:20    05/21    22:00            5000           500   \n",
      "4    1997/09/23      21:53    09/23    22:16            6000          2000   \n",
      "..          ...        ...      ...      ...             ...           ...   \n",
      "513  2017/09/04      20:27    09/05    04:54           14000           210   \n",
      "514  2017/09/06      12:05    09/07    08:00           16000            70   \n",
      "515  2017/09/10      16:02    09/11    06:50           16000           150   \n",
      "516  2017/09/12      07:38    09/12    07:43           16000         13000   \n",
      "517  2017/09/17      11:45    09/17    12:35           16000           900   \n",
      "\n",
      "    flare_location flare_region flare_classification cme_date cme_time  \\\n",
      "0           S25E16         8026                 M1.3    04/01    15:18   \n",
      "1           S28E19         8027                 C6.8    04/07    14:27   \n",
      "2           N21W08         8038                 C1.3    05/12    05:30   \n",
      "3           N05W12         8040                 M1.3    05/21    21:00   \n",
      "4           S29E25         8088                 C1.4    09/23    22:02   \n",
      "..             ...          ...                  ...      ...      ...   \n",
      "513         S10W12        12673                 M5.5    09/04    20:12   \n",
      "514         S08W33        12673                 X9.3    09/06    12:24   \n",
      "515         S09W92        -----                 X8.3    09/10    16:00   \n",
      "516         N08E48        12680                 C3.0    09/12    08:03   \n",
      "517        S08E170        -----                 ----    09/17    12:00   \n",
      "\n",
      "    cme_angle cme_width cme_speed  \n",
      "0          74        79       312  \n",
      "1        Halo       360       878  \n",
      "2        Halo       360       464  \n",
      "3         263       165       296  \n",
      "4         133       155       712  \n",
      "..        ...       ...       ...  \n",
      "513      Halo       360      1418  \n",
      "514      Halo       360      1571  \n",
      "515      Halo       360      3163  \n",
      "516       124        96       252  \n",
      "517      Halo       360      1385  \n",
      "\n",
      "[518 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# part 1\n",
    "## step 3\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "#http get request from NASA website. Table is parsed using BeautifulSoup and placed into dictionary.\n",
    "#Dictionary is placed into dataframe\n",
    "\n",
    "url = \"https://cdaw.gsfc.nasa.gov/CME_list/radio/waves_type2.html\"\n",
    "r = requests.get(url, headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X x.y; rv:42.0) Gecko/20100101 Firefox/42.0'})\n",
    "\n",
    "soup = BeautifulSoup(r.content, 'html')\n",
    "pre_data = soup.pre.get_text().splitlines()\n",
    "pre_data = pre_data[12:]\n",
    "\n",
    "\n",
    "lst = []\n",
    "for i in range(len(pre_data)):\n",
    "    lst.append(pre_data[i].split())\n",
    "\n",
    "dict = {'start_date':[], 'start_time':[], 'end_date':[], 'end_time':[], 'start_frequency':[],\n",
    "      'end_frequency':[], 'flare_location':[], 'flare_region':[], 'flare_classification':[], 'cme_date':[], \n",
    "        'cme_time':[], 'cme_angle':[],'cme_width':[], 'cme_speed':[]}\n",
    "\n",
    "for i in range(len(lst) - 1):\n",
    "    dict['start_date'].append(lst[i][0])\n",
    "    dict['start_time'].append(lst[i][1])\n",
    "    dict['end_date'].append(lst[i][2])\n",
    "    dict['end_time'].append(lst[i][3])\n",
    "    dict['start_frequency'].append(lst[i][4])\n",
    "    dict['end_frequency'].append(lst[i][5])\n",
    "    dict['flare_location'].append(lst[i][6])\n",
    "    dict['flare_region'].append(lst[i][7])\n",
    "    dict['flare_classification'].append(lst[i][8])\n",
    "    dict['cme_date'].append(lst[i][9])\n",
    "    dict['cme_time'].append(lst[i][10])\n",
    "    dict['cme_angle'].append(lst[i][11])\n",
    "    dict['cme_width'].append(lst[i][12])\n",
    "    dict['cme_speed'].append(lst[i][13])\n",
    "\n",
    "df3 = pd.DataFrame(dict)\n",
    "\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          start_datetime         end_datetime start_frequency end_frequency  \\\n",
      "0    1997-04-01 14:00:00  1997-04-01 14:15:00            8000          4000   \n",
      "1    1997-04-07 14:30:00  1997-04-07 17:30:00           11000          1000   \n",
      "2    1997-05-12 05:15:00  1997-05-14 16:00:00           12000            80   \n",
      "3    1997-05-21 20:20:00  1997-05-21 22:00:00            5000           500   \n",
      "4    1997-09-23 21:53:00  1997-09-23 22:16:00            6000          2000   \n",
      "..                   ...                  ...             ...           ...   \n",
      "513  2017-09-04 20:27:00  2017-09-05 04:54:00           14000           210   \n",
      "514  2017-09-06 12:05:00  2017-09-07 08:00:00           16000            70   \n",
      "515  2017-09-10 16:02:00  2017-09-11 06:50:00           16000           150   \n",
      "516  2017-09-12 07:38:00  2017-09-12 07:43:00           16000         13000   \n",
      "517  2017-09-17 11:45:00  2017-09-17 12:35:00           16000           900   \n",
      "\n",
      "    flare_location flare_region importance         cme_datetime  cpa width  \\\n",
      "0           S25E16         8026       M1.3  1997-04-01 15:18:00   74    79   \n",
      "1           S28E19         8027       C6.8  1997-04-07 14:27:00  NaN   360   \n",
      "2           N21W08         8038       C1.3  1997-05-12 05:30:00  NaN   360   \n",
      "3           N05W12         8040       M1.3  1997-05-21 21:00:00  263   165   \n",
      "4           S29E25         8088       C1.4  1997-09-23 22:02:00  133   155   \n",
      "..             ...          ...        ...                  ...  ...   ...   \n",
      "513         S10W12        12673       M5.5  2017-09-04 20:12:00  NaN   360   \n",
      "514         S08W33        12673       X9.3  2017-09-06 12:24:00  NaN   360   \n",
      "515         S09W92          NaN       X8.3  2017-09-10 16:00:00  NaN   360   \n",
      "516         N08E48        12680       C3.0  2017-09-12 08:03:00  124    96   \n",
      "517        S08E170          NaN        NaN  2017-09-17 12:00:00  NaN   360   \n",
      "\n",
      "    speed  plot  is_halo width_lower_bound  \n",
      "0     312  PHTX    False             False  \n",
      "1     878  PHTX     True             False  \n",
      "2     464  PHTX     True             False  \n",
      "3     296  PHTX    False             False  \n",
      "4     712  PHTX    False             False  \n",
      "..    ...   ...      ...               ...  \n",
      "513  1418  PHTX     True             False  \n",
      "514  1571  PHTX     True             False  \n",
      "515  3163  PHTX     True             False  \n",
      "516   252  PHTX    False             False  \n",
      "517  1385  PHTX     True             False  \n",
      "\n",
      "[518 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# part 1\n",
    "## step 4\n",
    "import datetime as dt\n",
    "\n",
    "#Deep copy dataframe from step 3. Tidying up table by setting missing data as NaN. Combined time and dates\n",
    "\n",
    "df4 = df3.copy()\n",
    "\n",
    "is_halo = []\n",
    "width_lower_bound = []\n",
    "\n",
    "for index, row in df4.iterrows():\n",
    "    df4['start_date'][index] = datetime.strptime(row['start_date'] + ' ' + row['start_time'], '%Y/%m/%d %H:%M')\n",
    "    df4['end_date'][index] = str(df4['start_date'][index].year) + '/' + df4['end_date'][index]\n",
    "    \n",
    "    #checking end_date and end_time\n",
    "    if row['end_time'].split(':')[0] == '24':\n",
    "        df4['end_time'][index] = '00:00'\n",
    "        \n",
    "        df4['end_date'][index] = pd.to_datetime(row['end_date'] + ' ' + row['end_time'], format='%Y/%m/%d %H:%M') + dt.timedelta(days=1)\n",
    "    else:\n",
    "        df4['end_date'][index] = datetime.strptime(row['end_date'] + ' ' + row['end_time'], '%Y/%m/%d %H:%M')\n",
    "    \n",
    "    df4['cme_date'][index] = str(df4['start_date'][index].year) + '/' + df4['cme_date'][index]\n",
    "    #checking cme_date and cme_time\n",
    "    if row['cme_date'].split('/')[0] == '--' or row['cme_date'].split('/')[1] == '--' or row['cme_time'].split(':')[0] == '--' or row['cme_time'].split(':')[1] == '--':\n",
    "        df4['cme_date'][index] = np.nan\n",
    "    else:\n",
    "        df4['cme_date'][index] = datetime.strptime(row['cme_date'] + ' ' + row['cme_time'], '%Y/%m/%d %H:%M')\n",
    "        \n",
    "    #checking cpa (cme_angle)\n",
    "    if not row['cme_angle'].isnumeric():\n",
    "        #making sure that that column is = 'Halo'\n",
    "        if(row['cme_angle'] == 'Halo'):\n",
    "            is_halo.append(True)\n",
    "        else:\n",
    "            is_halo.append(False)\n",
    "        df4['cme_angle'][index] = np.nan\n",
    "    else:\n",
    "        is_halo.append(False)\n",
    "        \n",
    "    #checking width (cme_width) and width_lower_bound\n",
    "    if '-' in row['cme_width']:\n",
    "        df4['cme_width'][index] = np.nan\n",
    "        width_lower_bound.append('false')\n",
    "    elif '>' in row['cme_width']:\n",
    "        df4['cme_width'][index] = df4['cme_width'][index][1:]\n",
    "        width_lower_bound.append(True)\n",
    "    else:\n",
    "        width_lower_bound.append(False)\n",
    "        \n",
    "    #checking for more missing data\n",
    "    if row['flare_location'].lower() == 'back' or '-' in row['flare_location']:\n",
    "        df4['flare_location'][index] = np.nan\n",
    "    if '-' in row['flare_region']:\n",
    "        df4['flare_region'][index] = np.nan\n",
    "    if '-' in row['flare_classification']:\n",
    "        df4['flare_classification'][index] = np.nan\n",
    "    if '-' in row['cme_speed']:\n",
    "        df4['cme_speed'][index] = np.nan\n",
    "    if '?' in df4['start_frequency']: \n",
    "        df4['start_frequency'][index] = np.nan\n",
    "    if '?' in df4['end_frequency']: \n",
    "        df4['end_frequency'][index] = np.nan\n",
    "        \n",
    "\n",
    "#delete columns\n",
    "df4 = df4.drop(columns=['start_time', 'end_time', 'cme_time'])\n",
    "#rename columns\n",
    "df4.rename(columns={'start_date':'start_datetime', 'end_date':'end_datetime','flare_classification':'importance', \n",
    "                    'cme_date':'cme_datetime', 'cme_angle':'cpa', 'cme_width':'width', 'cme_speed':'speed'}, \n",
    "           inplace=True)\n",
    "\n",
    "#adding plot, is_halo, and width_lower_bound columns\n",
    "plot = []\n",
    "for i in range(len(lst) - 1):\n",
    "    plot.append(lst[i][14])\n",
    "\n",
    "df4['plot'] = plot\n",
    "df4['is_halo'] = is_halo\n",
    "df4['width_lower_bound'] = width_lower_bound\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x_class      start_datetime        end_datetime region\n",
      "0     X28. 2003-11-04 20:00:00 2003-11-05 00:00:00  10486\n",
      "1     X20. 2001-04-02 22:05:00 2001-04-03 02:30:00   9393\n",
      "2     X17. 2003-10-28 11:10:00 2003-10-30 00:00:00  10486\n",
      "3     X14. 2001-04-15 14:05:00 2001-04-16 13:00:00   9415\n",
      "4     X10. 2003-10-29 20:55:00 2003-10-30 00:00:00  10486\n",
      "5     X9.4 1997-11-06 12:20:00 1997-11-07 08:30:00   8100\n",
      "6     X9.3 2017-09-06 12:05:00 2017-09-07 08:00:00  12673\n",
      "7     X9.0 2006-12-05 10:50:00 2006-12-05 20:00:00  10930\n",
      "8     X8.3 2003-11-02 17:30:00 2003-11-03 01:00:00  10486\n",
      "9     X8.3 2017-09-10 16:02:00 2017-09-11 06:50:00    NaN\n",
      "10    X7.1 2005-01-20 07:15:00 2005-01-20 16:30:00  10720\n",
      "11    X6.9 2011-08-09 08:20:00 2011-08-09 08:35:00  11263\n",
      "12    X6.5 2006-12-06 19:00:00 2006-12-09 00:00:00  10930\n",
      "13    X6.2 2005-09-09 19:45:00 2005-09-09 22:00:00  10808\n",
      "14    X5.7 2000-07-14 10:30:00 2000-07-15 14:30:00   9077\n",
      "15    X5.6 2001-04-06 19:35:00 2001-04-07 01:50:00   9415\n",
      "16    X5.4 2012-03-07 01:00:00 2012-03-08 19:00:00  11429\n",
      "17    X5.3 2001-08-25 16:50:00 2001-08-25 23:00:00   9591\n",
      "18    X4.9 2014-02-25 00:56:00 2014-02-25 11:28:00  11990\n",
      "19    X4.8 2002-07-23 00:50:00 2002-07-23 04:00:00  10039\n",
      "20    X4.0 2000-11-26 17:00:00 2000-11-26 17:15:00   9236\n",
      "21    X3.9 2003-11-03 10:00:00 2003-11-03 12:30:00  10488\n",
      "22    X3.8 2005-01-17 10:00:00 2005-01-17 10:35:00  10720\n",
      "23    X3.6 2003-05-28 01:00:00 2003-05-29 00:30:00  10365\n",
      "24    X3.4 2006-12-13 02:45:00 2006-12-13 10:40:00  10930\n",
      "25    X3.4 2001-12-28 20:35:00 2001-12-29 03:00:00   9756\n",
      "26    X3.3 2002-07-20 21:30:00 2002-07-20 22:20:00  10039\n",
      "27    X3.2 2013-05-14 01:16:00 2013-05-14 08:20:00  11748\n",
      "28    X3.1 2002-08-24 01:45:00 2002-08-24 03:25:00  10069\n",
      "29    X2.8 2013-05-13 16:15:00 2013-05-13 19:10:00  11748\n",
      "30    X2.7 2015-05-05 22:24:00 2015-05-05 23:14:00  12339\n",
      "31    X2.7 1998-05-06 08:25:00 1998-05-06 08:35:00   8210\n",
      "32    X2.7 2003-11-03 01:15:00 2003-11-03 01:25:00  10488\n",
      "33    X2.6 2005-01-15 23:00:00 2005-01-17 00:00:00  10720\n",
      "34    X2.6 2001-09-24 10:45:00 2001-09-25 20:00:00   9632\n",
      "35    X2.6 1997-11-27 13:30:00 1997-11-27 14:00:00   8113\n",
      "36    X2.5 2004-11-10 02:25:00 2004-11-10 03:40:00  10696\n",
      "37    X2.3 2001-04-10 05:24:00 2001-04-11 00:00:00   9415\n",
      "38    X2.3 2000-11-24 15:25:00 2000-11-24 22:00:00   9236\n",
      "39    X2.3 2000-06-06 15:20:00 2000-06-08 09:00:00   9026\n",
      "40    X2.2 2011-02-15 02:10:00 2011-02-15 07:00:00  11158\n",
      "41    X2.1 2005-09-10 21:45:00 2005-09-11 01:00:00  10808\n",
      "42    X2.1 2011-09-06 22:30:00 2011-09-07 15:40:00  11283\n",
      "43    X2.1 2013-10-25 15:08:00 2013-10-25 22:32:00  11882\n",
      "44    X2.1 1997-11-04 06:00:00 1997-11-05 04:30:00   8100\n",
      "45    X2.0 2000-11-24 05:10:00 2000-11-24 15:00:00   9236\n",
      "46    X2.0 2001-04-12 10:20:00 2001-04-12 10:40:00   9415\n",
      "47    X2.0 2004-11-07 16:25:00 2004-11-08 20:00:00  10696\n",
      "48    X2.0 2005-01-17 09:25:00 2005-01-17 16:00:00  10720\n",
      "49    X1.9 2000-11-25 19:00:00 2000-11-25 19:35:00   9236\n"
     ]
    }
   ],
   "source": [
    "# part 2\n",
    "## question 1\n",
    "\n",
    "#You cannot replicate the SpaceLiveWeather data exactly by taking the top 50 X-class from the NASA website. \n",
    "#Some of the solar flares on the SLW website are not recorded on the NASA website and vice versa, \n",
    "#although there are many matches.\n",
    "\n",
    "temp = {'power': [], 'x_class': [], 'start_datetime': [], 'end_datetime': [], 'region': []}\n",
    "for index, row in df4.iterrows():\n",
    "    if row['importance'] is not np.nan and 'X' in row['importance']:\n",
    "        x_class = row['importance']\n",
    "        if x_class[len(x_class) - 1] == '.':\n",
    "            x_class = x_class[:-1]\n",
    "        temp['power'].append(float(x_class[1:]))\n",
    "        temp['start_datetime'].append(row['start_datetime'])\n",
    "        temp['end_datetime'].append(row['end_datetime'])\n",
    "        temp['x_class'].append(row['importance'])\n",
    "        temp['region'].append(row['flare_region'])\n",
    "\n",
    "df_temp = pd.DataFrame(temp)\n",
    "df_temp = df_temp.sort_values(by = 'power', ascending = False)\n",
    "df_temp = df_temp.reset_index(drop=True)\n",
    "\n",
    "top = {'x_class': df_temp['x_class'][:50], 'start_datetime': df_temp['start_datetime'][:50], \n",
    "       'end_datetime': df_temp['end_datetime'][:50], 'region': df_temp['region'][:50]}\n",
    "\n",
    "df_top = pd.DataFrame(top)\n",
    "print(df_top)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   importance      start_datetime        end_datetime start_frequency width  \\\n",
      "0        X28. 2003-11-04 20:00:00 2003-11-05 00:00:00           10000   360   \n",
      "1        X20. 2001-04-02 22:05:00 2001-04-03 02:30:00           14000   244   \n",
      "2        X17. 2003-10-28 11:10:00 2003-10-30 00:00:00           14000   360   \n",
      "3        X1.7 2005-09-07 18:05:00 2005-09-08 00:00:00           12000   NaN   \n",
      "4        X14. 2001-04-15 14:05:00 2001-04-16 13:00:00           14000   167   \n",
      "5        X10. 2003-10-29 20:55:00 2003-10-30 00:00:00           11000   360   \n",
      "6        X9.4 1997-11-06 12:20:00 1997-11-07 08:30:00           14000   360   \n",
      "7        X9.3 2017-09-06 12:05:00 2017-09-07 08:00:00           16000   360   \n",
      "8        X9.0 2006-12-05 10:50:00 2006-12-05 20:00:00           14000   NaN   \n",
      "9        X8.3 2003-11-02 17:30:00 2003-11-03 01:00:00           12000   360   \n",
      "10       X8.3 2017-09-10 16:02:00 2017-09-11 06:50:00           16000   360   \n",
      "11       X7.1 2005-01-20 07:15:00 2005-01-20 16:30:00           14000   360   \n",
      "12       X6.9 2011-08-09 08:20:00 2011-08-09 08:35:00           16000   360   \n",
      "13       X6.5 2006-12-06 19:00:00 2006-12-09 00:00:00           16000   NaN   \n",
      "14       X6.2 2005-09-09 19:45:00 2005-09-09 22:00:00           10000   360   \n",
      "15       X6.2 2005-09-09 19:45:00 2005-09-09 22:00:00           10000   360   \n",
      "16       X5.7 2000-07-14 10:30:00 2000-07-15 14:30:00           14000   360   \n",
      "17       X5.6 2001-04-06 19:35:00 2001-04-07 01:50:00           14000   360   \n",
      "18       X5.4 2012-03-07 01:00:00 2012-03-08 19:00:00           16000   360   \n",
      "19       C1.4 1997-09-23 21:53:00 1997-09-23 22:16:00            6000   155   \n",
      "20       X5.7 2000-07-14 10:30:00 2000-07-15 14:30:00           14000   360   \n",
      "21       X5.3 2001-08-25 16:50:00 2001-08-25 23:00:00            8000   360   \n",
      "22       X4.9 2014-02-25 00:56:00 2014-02-25 11:28:00           14000   360   \n",
      "23       X4.0 2000-11-26 17:00:00 2000-11-26 17:15:00           14000   360   \n",
      "24       X4.8 2002-07-23 00:50:00 2002-07-23 04:00:00           11000   360   \n",
      "25       X4.0 2000-11-26 17:00:00 2000-11-26 17:15:00           14000   360   \n",
      "26       X3.9 2003-11-03 10:00:00 2003-11-03 12:30:00            6000   103   \n",
      "27       X3.4 2001-12-28 20:35:00 2001-12-29 03:00:00           14000   360   \n",
      "28       X3.8 2005-01-17 10:00:00 2005-01-17 10:35:00            6100   360   \n",
      "29       X3.4 2001-12-28 20:35:00 2001-12-29 03:00:00           14000   360   \n",
      "30       X6.2 2005-09-09 19:45:00 2005-09-09 22:00:00           10000   360   \n",
      "31       X3.4 2001-12-28 20:35:00 2001-12-29 03:00:00           14000   360   \n",
      "32       X3.6 2003-05-28 01:00:00 2003-05-29 00:30:00            1000   360   \n",
      "33       X3.4 2006-12-13 02:45:00 2006-12-13 10:40:00           12000   360   \n",
      "34       X3.4 2001-12-28 20:35:00 2001-12-29 03:00:00           14000   360   \n",
      "35       X3.4 2001-12-28 20:35:00 2001-12-29 03:00:00           14000   360   \n",
      "36       X3.3 2002-07-20 21:30:00 2002-07-20 22:20:00           10000   360   \n",
      "37       X3.4 2001-12-28 20:35:00 2001-12-29 03:00:00           14000   360   \n",
      "38       X3.2 2013-05-14 01:16:00 2013-05-14 08:20:00           16000   360   \n",
      "39       X3.4 2001-12-28 20:35:00 2001-12-29 03:00:00           14000   360   \n",
      "40       X3.1 2002-08-24 01:45:00 2002-08-24 03:25:00            5000   360   \n",
      "41       M1.8 2002-07-15 21:15:00 2002-07-16 05:00:00            5000   188   \n",
      "42       X2.8 2013-05-13 16:15:00 2013-05-13 19:10:00           16000   360   \n",
      "43       X2.1 1997-11-04 06:00:00 1997-11-05 04:30:00           14000   360   \n",
      "44       X2.1 1997-11-04 06:00:00 1997-11-05 04:30:00           14000   360   \n",
      "45       X2.7 2015-05-05 22:24:00 2015-05-05 23:14:00           14000   360   \n",
      "46       X2.7 2003-11-03 01:15:00 2003-11-03 01:25:00            3000    65   \n",
      "47       X2.7 1998-05-06 08:25:00 1998-05-06 08:35:00           14000   190   \n",
      "48       X2.6 2005-01-15 23:00:00 2005-01-17 00:00:00            3000   360   \n",
      "49       X2.6 2001-09-24 10:45:00 2001-09-25 20:00:00            7000   360   \n",
      "\n",
      "   region speed  is_halo  \n",
      "0   10486  2657     True  \n",
      "1    9393  2505    False  \n",
      "2   10486  2459     True  \n",
      "3   10808   NaN    False  \n",
      "4    9415  1199    False  \n",
      "5   10486  2029     True  \n",
      "6    8100  1556     True  \n",
      "7   12673  1571     True  \n",
      "8   10930   NaN    False  \n",
      "9   10486  2598     True  \n",
      "10    NaN  3163     True  \n",
      "11  10720   882     True  \n",
      "12  11263  1610     True  \n",
      "13  10930   NaN    False  \n",
      "14  10808  2257     True  \n",
      "15  10808  2257     True  \n",
      "16   9077  1674     True  \n",
      "17   9415  1270     True  \n",
      "18  11429  2684     True  \n",
      "19   8088   712    False  \n",
      "20   9077  1674     True  \n",
      "21   9591  1433     True  \n",
      "22  11990  2147     True  \n",
      "23   9236   980     True  \n",
      "24  10039  2285     True  \n",
      "25   9236   980     True  \n",
      "26  10488  1420    False  \n",
      "27   9756  2216     True  \n",
      "28  10720  2547     True  \n",
      "29   9756  2216     True  \n",
      "30  10808  2257     True  \n",
      "31   9756  2216     True  \n",
      "32  10365  1366     True  \n",
      "33  10930  1774     True  \n",
      "34   9756  2216     True  \n",
      "35   9756  2216     True  \n",
      "36  10039  1941     True  \n",
      "37   9756  2216     True  \n",
      "38  11748  2625     True  \n",
      "39   9756  2216     True  \n",
      "40  10069  1913     True  \n",
      "41  10030  1300    False  \n",
      "42  11748  1850     True  \n",
      "43   8100   785     True  \n",
      "44   8100   785     True  \n",
      "45  12339   715     True  \n",
      "46  10488   827    False  \n",
      "47   8210  1099    False  \n",
      "48  10720  2861     True  \n",
      "49   9632  2402     True  \n"
     ]
    }
   ],
   "source": [
    "# part 2\n",
    "## question 2\n",
    "\n",
    "#Two rows match if at least one of their columns match. The columns are importance, start_datetime, end_datetime,\n",
    "#width, region, and speed. The number of column matches between the SpaceLiveWeather website and the NASA website are\n",
    "#counted. Each row in the top 50 SpaceLiveWeather website is matched with the row of the first occurence of the \n",
    "#highest number of matches on the NASA website. \n",
    "\n",
    "total = 0\n",
    "matching = {'importance': [], 'start_datetime': [], 'end_datetime': [], 'start_frequency': [], 'width': [], \n",
    "          'region': [], 'speed': [], 'is_halo': []}\n",
    "\n",
    "for df2_i, df2_r in df2.iterrows():\n",
    "    match = 0\n",
    "    index = 0\n",
    "    for df4_i, df4_r in df4.iterrows():\n",
    "        count = 0\n",
    "        x_class = df2_r['x_class'].split('.')\n",
    "        if x_class[0][len(x_class[0]) - 1] == '+':\n",
    "            x_class[0] = x_class[0][:-1]\n",
    "        imp = str(df4_r['importance']).split('.')\n",
    "        if imp[0][len(imp[0]) - 1] == '.':\n",
    "            imp = imp[:-1]\n",
    "        elif imp[0][len(imp[0]) - 2:len(imp[0]) - 1] == '.0':\n",
    "            imp = imp[:-2]\n",
    "            \n",
    "        if imp[0] == x_class[0]:\n",
    "            count += 1\n",
    "        if str(df2_r['region']) in str(df4_r['flare_region']):\n",
    "            count += 1   \n",
    "        if df2_r['start_datetime'].strftime(\"%Y-%m-%d\") == df4_r['start_datetime'].strftime(\"%Y-%m-%d\"):\n",
    "            count += 1\n",
    "        if df2_r['start_datetime'].strftime(\"%H:%M\") == df4_r['start_datetime'].strftime(\"%H:%M\"):\n",
    "            count += 1\n",
    "        if count > match:\n",
    "            match = count\n",
    "            index = df4_i\n",
    "    total += 1\n",
    "    matching['importance'].append(str(df4['importance'][index]))\n",
    "    matching['start_datetime'].append(df4['start_datetime'][index])\n",
    "    matching['end_datetime'].append(df4['end_datetime'][index])\n",
    "    matching['start_frequency'].append(df4['start_frequency'][index])\n",
    "    matching['width'].append(df4['width'][index])\n",
    "    matching['region'].append(df4['flare_region'][index])\n",
    "    matching['speed'].append(df4['speed'][index])\n",
    "    matching['is_halo'].append(df4['is_halo'][index])\n",
    "\n",
    "df_match = pd.DataFrame(matching)\n",
    "print(df_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# part 2\n",
    "## question 3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#The goal of the following plot is to determine if the top 50 solar flares from the NASA table tend to have more halo \n",
    "#CMEs by displaying the proportion of Halo CMEs between the top 50 solar flares and the whole dataset. \n",
    "#Because both datasets are different in size, we will use proportion instead of number of CMEs\n",
    "\n",
    "num_halo_top50 = 0\n",
    "for index, row in df_match.iterrows():\n",
    "    if row['is_halo']:\n",
    "        num_halo_top50 += 1\n",
    "\n",
    "num_halo_NASA = 0\n",
    "for index, row in df4.iterrows():\n",
    "    if row['is_halo']:\n",
    "        num_halo_NASA += 1\n",
    "\n",
    "#number of Halo CME's from NASA's top 50\n",
    "barplot = {'dataset': ['top50', 'NASA'], 'proportion': []}\n",
    "barplot['proportion'].append(num_halo_top50 / len(df_match['importance']))\n",
    "barplot['proportion'].append(num_halo_NASA / len(df4['importance']))\n",
    "df_barplot = pd.DataFrame(barplot)\n",
    "\n",
    "#In the x-axis, we have the source of our data. It is between top 50 solar flares and the whole dataset both from NASA\n",
    "#In the y-axis, we have the proportion of Halo CMEs from the two sources\n",
    "df_barplot.plot(x = 'dataset', y = 'proportion', kind = 'bar')\n",
    "\n",
    "#According to the bar graph, the top 50 flares tend to have solar CMEs\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
